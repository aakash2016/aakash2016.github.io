---
layout: archive
permalink: /reflections/cse291h/
author_profile: true
---

<div style="display: flex; align-items: center; font-size: 14px; font-family: 'Times New Roman', Times, serif; color:rgb(0, 0, 0); margin-top: 15px;">
    Sharing my Reflections on the courses I took as a Data Science major (MS) student at UCSD
</div>

<div style="justify-content: center; align-items: center; font-family: 'Times New Roman', Times, serif;">
  <div style="flex: 1; font-size: 14px; color: #212f3c;">
    <h3 style="color: #1e3a8a; font-size: 24px; font-family: 'Times New Roman', Times, serif;">CSE291h: Advanced Data-driven Text Mining</h3>
    <p><strong style="color: black; font-size: 16px;">Instructor: Prof. Jingbo Shang </strong></p>
    <div style="text-align: center;">
      <figure style="display: inline-block; text-align: center; position: relative;">
        <img src="/assets/images/cse291h.jpg" alt="CSE 291h Course Logo" style="width: 500px; height: auto;">
        <figcaption style="font-size: 12px; color: #555;">Slides from Prof Shang's class</figcaption>
      </figure>
    </div>
    <p style="font-size: 14px; color: #212f3c; text-align: justify;">
      This course covered a wide range of NLP topics, starting with foundational concepts such as frequency-based word embeddings, and progressing to prediction-based embeddings (Word2Vec, GloVe), language models (including neural language models), and their respective advantages and limitations. The course also delved into Sentiment Analysis, Information Retrieval, and LLMs in fair detail, providing a solid foundation for understanding these advanced topics.<br><br>
      One of the highlights was learning about the professor’s own work in <strong>Phrase Mining</strong>, which enhances feature representation and improves textual understanding. This included an exploration of three methods for phrase mining: supervised, unsupervised, and weakly/distantly supervised learning, a new concept for me. As part of the assignments, I applied techniques such as SegPhrase (<strong>weakly supervised</strong>, using manually annotated labels) and AutoPhrase (<strong>distantly supervised</strong>, leveraging existing knowledge bases like Wikipedia) for mining phrases.<br><br>
      Additionally, the professor organized a graded Kaggle competition focused on multi-class text classification. This was a challenging and intensive experience, where I experimented with various embedding and modeling techniques to achieve a strong score. Overall, I found this course highly beneficial as a Data Science major. While it doesn’t focus directly on the latest hot topics like LLMs, it provides a robust understanding that is essential for working with these models in the future.
    </p>
    <p style="font-size: 14px; color: #ec407a;">Fall 2024</p>
  </div>
</div>
